# DataStor Case Study

This case is about analyzing the quality control process at DataStor, a company that produces hard drives. The focus is on identifying potential quality problems using statistical methods. The company uses a PDQ test score to assess the quality of their drives, and they reject any drive with a score below 6.2. The analysis starts by reviewing the distribution of various data points, such as hours worked by production employees, the number of drives produced, and the average PDQ score.

The initial analysis shows that the data doesn't indicate any major issues, and the distribution of scores appears normal. However, when examining the probability of a drive being defective (score below 6.2), the calculations suggest that around 4 out of every 1,000 drives will fail. This leads to an investigation into the rejection of shipments, revealing that DataStor is rejecting shipments at a much higher rate than expected, indicating a potential quality issue.

Further analysis includes examining control charts, which show that the process may indeed be out of control. The analysis also identifies that the problem is particularly pronounced in Shift 3, where the quality of the drives produced is worse than in Shift 1 and Shift 2.

In summary, the case is about using statistical analysis to identify quality issues in the production process, and while the problem is clear, the exact source of the issue remains unclear, though it seems related to the specific shift when the drives are produced.
